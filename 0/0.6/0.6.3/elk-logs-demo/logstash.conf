input {
  file {
    path => "/usr/share/logstash/logs/network_logs.csv"
    start_position => "beginning"
    sincedb_path => "/dev/null"
  }
}

filter {
  csv {
    separator => ","
    skip_header => "true"
    columns => ["date_first_seen","duration","proto","src_ip","src_port",
                "dst_ip","dst_port","packets","bytes","flows","flags",
                "tos","class","attackType","attackID","attackDescription"]
  }

  # Normalizamos el campo de tiempo -> lo pasamos a @timestamp
  date {
    match => ["date_first_seen", "yyyy-MM-dd HH:mm:ss.SSS"]
    target => "@timestamp"
  }

  # Convertimos mÃ©tricas a numÃ©ricas
  mutate {
    convert => {
      "duration" => "float"
      "packets" => "integer"
      "bytes" => "integer"
      "flows" => "integer"
    }
  }
}

output { 
  elasticsearch { 
    hosts => ["http://elasticsearch:9200"] 
    index => "network-flows-%{+YYYY.MM.dd}" 
  } 
  stdout { codec => rubydebug } 
}